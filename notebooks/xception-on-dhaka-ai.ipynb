{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imbalanced-learn\n!pip install seaborn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport h5py\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nimport seaborn as sns\nfrom tensorflow.keras.applications.xception import Xception, preprocess_input\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import classification_report, roc_curve, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nread_data = \"/kaggle/input/dhakaai/dhakaai-dataset.h5\"\nwith h5py.File(read_data, 'r') as hf:\n    image = hf['images'][:]\n    label = hf['labels'][:]\n    valid_indices = [i for i, lbl in enumerate(label) if lbl != b'taxi']\n\n    images = image[valid_indices]\n    labels = label[valid_indices]\n       \nprint('Total number of images: ',len(images))\nprint('Total number of labels: ',len(labels))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_classes, class_counts = np.unique(labels, return_counts=True)\nfor class_label, count in zip(unique_classes, class_counts):\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"desired_size = (224, 224)\n\nnum_images = len(images)\nresized_images = np.empty((num_images,) + desired_size + (3,), dtype=np.uint8)\n\nfor i, image in enumerate(images):\n    resized_pil_image = Image.fromarray((image * 255).astype(np.uint8)).resize(desired_size)\n    resized_images[i] = np.array(resized_pil_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_low_samples = 1045\n\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\nlabel_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n\nflattened_images_reshaped = np.array([img.flatten() for img in resized_images])\nnum_samples, num_features = flattened_images_reshaped.shape\n\noversampled_images = []\noversampled_labels = []\n\nto_sample_images = []\nto_sample_labels = []\n\nunique_classes, class_counts = np.unique(encoded_labels, return_counts=True)\n\nfor class_label, count in zip(unique_classes, class_counts):\n    class_indices = np.where(encoded_labels == class_label)[0]\n    \n    if count <= threshold_low_samples:\n        to_sample_images.extend(flattened_images_reshaped[class_indices])\n        to_sample_labels.extend(encoded_labels[class_indices])\n\nif len(to_sample_images) >= 3:\n    smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=2)\n    oversampled_class_images, oversampled_class_labels = smote.fit_resample(to_sample_images, to_sample_labels)\n\n    oversampled_images.extend(oversampled_class_images)\n    oversampled_labels.extend(oversampled_class_labels)\n    \noriginal_images = np.array(oversampled_images, dtype=np.uint8).reshape(-1, 224,224,3)\nprint('Total number of sampled images: ',len(original_images))\nprint('Total number of sampled labels: ',len(oversampled_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_classes_aug, class_counts_aug = np.unique(oversampled_labels, return_counts=True)\nfor class_label, count in zip(unique_classes_aug, class_counts_aug):\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = len(np.unique(oversampled_labels))\nprint('Number of classes',num_classes)\n\nlabel = torch.tensor(oversampled_labels)\nlabels = nn.functional.one_hot(label, num_classes=num_classes)\nlabels = labels.float()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        x = self.data[index]\n        y = self.labels[index]\n\n        if self.transform:\n            x = self.transform(x)\n\n        return x, y\ntransform = transforms.Compose([\n\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n\ndataset = ImageDataset(original_images, labels, transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.efficientnet_v2_s(pretrained=True)  # Note the model name\nmodel.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes)\n\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    model.cuda()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0001\nepochs = 3\nbatch_size = 32\nk = 3\n\nkf = KFold(n_splits=k, shuffle=True)\naccuracy_values = []\nweighted_precision_values = []\nweighted_recall_values = []\nweighted_f1_score_values = []\n\n\nall_true_labels = []\nall_pred_labels = []\nconfusion_matrices = []\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\nfor fold, (train_index, test_index) in enumerate(kf.split(dataset), 1):\n    print(\"Fold:\", fold)\n    train_sampler = torch.utils.data.SubsetRandomSampler(train_index)\n    test_sampler = torch.utils.data.SubsetRandomSampler(test_index)\n\n    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n    test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for batch_idx, (inputs, labels) in enumerate(train_loader):\n          inputs = inputs.to(device)\n          labels = labels.to(device)\n          outputs = model(inputs)\n          loss = criterion(outputs, labels)\n          optimizer.zero_grad()\n          loss.backward()\n          optimizer.step()\n          running_loss += loss.item()\n\n          print(f\"\\rEpoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\", end='')\n\n        print(f\"\\rEpoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n\n    model.eval()\n    y_true = []\n    y_pred = []\n\n    for batch_idx, (inputs, labels) in enumerate(test_loader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        predicted = F.softmax(outputs, dim=1)\n\n        y_true.extend(labels.cpu().tolist())\n        y_pred.extend(predicted.cpu().tolist())\n\n    print(f\"\\rEvaluation: Batch {batch_idx+1}/{len(test_loader)}\", end='\\n')\n    \n    y_true_labels = np.argmax(y_true, axis=1)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    \n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    report = classification_report(y_true_labels, y_pred_labels, output_dict=True)\n\n    confusion_matrices.append(cm)\n    accuracy_values.append(report['accuracy'])\n    weighted_precision_values.append(report['weighted avg']['precision'])\n    weighted_recall_values.append(report['weighted avg']['recall'])\n    weighted_f1_score_values.append(report['weighted avg']['f1-score'])\n    \n    all_true_labels.extend(y_true_labels)\n    all_pred_labels.extend(y_pred)\n\n\navg_accuracy = np.mean(accuracy_values)\navg_weighted_precision = np.mean(weighted_precision_values)\navg_weighted_recall = np.mean(weighted_recall_values)\nweighted_f1_score_values = np.mean(weighted_f1_score_values)\n\nprint('Average accuracy:', avg_accuracy)\nprint('Average weighted precision:', avg_weighted_precision)\nprint('Average weighted recall:', avg_weighted_recall)\nprint('Average weighted f1_score:', weighted_f1_score_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pred_labels = np.array(all_pred_labels)\nall_true_labels = np.array(all_true_labels)\nn_classes = len(np.unique(all_true_labels))\nall_true_labels_binarized = label_binarize(all_true_labels, classes=range(n_classes))\ntrue = all_true_labels_binarized.ravel()\npred = all_pred_labels.ravel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = pd.DataFrame({\n    'True_Class': true,\n    'Pred_Class': pred,\n})\n\nmodel = 'Xception'\ndataset = 'DhakaAI'\n\nroc_values.to_csv(f'/kaggle/working/{dataset}_{model}_ROC.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_curves = pd.DataFrame({\n    'Precision': weighted_precision_values,\n    'Recall': weighted_recall_values,\n    'F1_score': weighted_f1_score_values,\n})\n\nmodel = 'Xception'\ndataset = 'DhakaAI'\n\nlearning_curves.to_csv(f'/kaggle/working/{dataset}_{model}_Learning.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = 'Xception'\ndataset = 'DhakaAI'\n\ncombined_conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n\nfor fold, cm in enumerate(confusion_matrices, 1):\n    combined_conf_matrix += cm\n\nconf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(25, num_labels * 0.5), 30)\nfig_height = max(10, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=45, fontsize=10)\nplt.yticks(rotation=0, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig(f'/kaggle/working/confusion_matrix1-{dataset}_{model}.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = 'Xception'\ndataset = 'DhakaAI'\n\nconf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(25, num_labels * 0.5), 30)\nfig_height = max(20, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=45, fontsize=10)\nplt.yticks(rotation=45, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=10)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig(f'/kaggle/working/confusion_matrix2-{dataset}_{model}.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}