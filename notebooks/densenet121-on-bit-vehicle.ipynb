{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6330408,"sourceType":"datasetVersion","datasetId":3643729}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T06:41:48.398537Z","iopub.execute_input":"2023-08-21T06:41:48.399249Z","iopub.status.idle":"2023-08-21T06:41:54.484042Z","shell.execute_reply.started":"2023-08-21T06:41:48.399209Z","shell.execute_reply":"2023-08-21T06:41:54.482643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:41:54.486382Z","iopub.execute_input":"2023-08-21T06:41:54.486727Z","iopub.status.idle":"2023-08-21T06:42:36.329016Z","shell.execute_reply.started":"2023-08-21T06:41:54.486695Z","shell.execute_reply":"2023-08-21T06:42:36.327968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with h5py.File('/kaggle/input/bit-vehicle/bitvehicle_dataset.h5', 'r') as file:\n    images = file['images'][:]\n    labels = file['labels'][:]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:43:20.696660Z","iopub.execute_input":"2023-08-21T06:43:20.697040Z","iopub.status.idle":"2023-08-21T06:43:59.385181Z","shell.execute_reply.started":"2023-08-21T06:43:20.697009Z","shell.execute_reply":"2023-08-21T06:43:59.384113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of images: ',len(images))\nprint('Total number of labels: ',len(labels))\n\nunique_classes, class_counts = np.unique(labels, return_counts=True)\nfor class_label, count in zip(unique_classes, class_counts):\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:43:59.387000Z","iopub.execute_input":"2023-08-21T06:43:59.387325Z","iopub.status.idle":"2023-08-21T06:43:59.398718Z","shell.execute_reply.started":"2023-08-21T06:43:59.387298Z","shell.execute_reply":"2023-08-21T06:43:59.397875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_images = [Image.fromarray(image).resize((224, 224)) for image in images]\nresized_images = np.array([preprocess_input(np.array(image)) for image in resized_images])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:43:59.399728Z","iopub.execute_input":"2023-08-21T06:43:59.399995Z","iopub.status.idle":"2023-08-21T06:44:31.542698Z","shell.execute_reply.started":"2023-08-21T06:43:59.399971Z","shell.execute_reply":"2023-08-21T06:44:31.541777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_brightness(image, factor):\n    image = image.astype(np.float32)\n    augmented_image = image + factor\n    augmented_image = np.clip(augmented_image, 0, 255)\n    augmented_image = augmented_image.astype(np.uint8)\n    return augmented_image\n\ndef flip_image(image, flip_code):\n    return cv2.flip(image, flip_code)\n\ndef rotate_image(image, angle):\n    rows, cols = image.shape[:2]\n    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n    return cv2.warpAffine(image, M, (cols, rows))\n\ndef zoom_image(image, zoom_factor):\n    rows, cols = image.shape[:2]\n    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 0, zoom_factor)\n    return cv2.warpAffine(image, M, (cols, rows))\n\ndef shift_image(image, dx, dy):\n    rows, cols = image.shape[:2]\n    M = np.float32([[1, 0, dx], [0, 1, dy]])\n    return cv2.warpAffine(image, M, (cols, rows))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:44:39.254646Z","iopub.execute_input":"2023-08-21T06:44:39.255007Z","iopub.status.idle":"2023-08-21T06:44:39.265709Z","shell.execute_reply.started":"2023-08-21T06:44:39.254978Z","shell.execute_reply":"2023-08-21T06:44:39.264893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_images = []\naugmented_labels = []\n\nfor img, label in zip(resized_images, labels):\n    if label == b'Bus':\n        augmented_img_brightness = adjust_brightness(img, 50)\n        augmented_img_flip_horizontal = flip_image(img, 1)\n        augmented_img_flip_vertical = flip_image(img, 0)\n        augmented_img_rotate = rotate_image(img, 30)\n        augmented_img_zoom = zoom_image(img, 1.2)\n        augmented_img_shift = shift_image(img, 20, 20)\n        augmented_images.extend([\n            augmented_img_brightness,\n            augmented_img_flip_horizontal,\n            augmented_img_flip_vertical,\n            augmented_img_rotate,\n            augmented_img_zoom,\n            augmented_img_shift,\n        ])\n        augmented_labels.extend([label] * 6)\n    if label == b'Minivan':\n        augmented_img_brightness = adjust_brightness(img, 50)\n        augmented_img_flip_horizontal = flip_image(img, 1)\n        augmented_img_flip_vertical = flip_image(img, 0)\n        augmented_img_rotate = rotate_image(img, 30)\n        augmented_img_zoom = zoom_image(img, 1.2)\n        augmented_img_shift = shift_image(img, 20, 20)\n        augmented_images.extend([\n            augmented_img_brightness,\n            augmented_img_flip_horizontal,\n            augmented_img_flip_vertical,\n            augmented_img_rotate,\n            augmented_img_zoom,\n            augmented_img_shift,\n        ])\n        augmented_labels.extend([label] * 6)\n        \n    if label == b'Microbus':\n        augmented_img_flip_horizontal = flip_image(img, 1)\n        augmented_img_flip_vertical = flip_image(img, 0)\n        augmented_images.extend([\n            augmented_img_flip_horizontal,\n            augmented_img_flip_vertical,\n        ])\n        augmented_labels.extend([label] * 2)\n    \n    if label == b'SUV':\n        augmented_img_rotate = rotate_image(img, 30)\n        augmented_images.extend([\n            augmented_img_rotate,\n        ])\n        augmented_labels.extend([label] * 1)\n        \n    if label == b'Truck':\n        augmented_img_flip_horizontal = flip_image(img, 1)\n        augmented_img_flip_vertical = flip_image(img, 0)\n        augmented_img_rotate = rotate_image(img, 30)\n        augmented_images.extend([\n            augmented_img_flip_horizontal,\n            augmented_img_flip_vertical,\n            augmented_img_rotate,\n        ])\n        augmented_labels.extend([label] * 3)\n\n    else:\n        augmented_images.append(img)\n        augmented_labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:44:39.557452Z","iopub.execute_input":"2023-08-21T06:44:39.557761Z","iopub.status.idle":"2023-08-21T06:44:45.963764Z","shell.execute_reply.started":"2023-08-21T06:44:39.557734Z","shell.execute_reply":"2023-08-21T06:44:45.962818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of augmented images: ',len(augmented_images))\nprint('Total number of augmented labels: ',len(augmented_labels))\n\nunique_classes_aug, class_counts_aug = np.unique(augmented_labels, return_counts=True)\nfor class_label, count in zip(unique_classes_aug, class_counts_aug):\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:44:45.965255Z","iopub.execute_input":"2023-08-21T06:44:45.965566Z","iopub.status.idle":"2023-08-21T06:44:45.975229Z","shell.execute_reply.started":"2023-08-21T06:44:45.965527Z","shell.execute_reply":"2023-08-21T06:44:45.974473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.array(augmented_images)\nnum_classes = len(np.unique(augmented_labels))\nprint('Number of classes',num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:45:06.804038Z","iopub.execute_input":"2023-08-21T06:45:06.805056Z","iopub.status.idle":"2023-08-21T06:45:10.587348Z","shell.execute_reply.started":"2023-08-21T06:45:06.805015Z","shell.execute_reply":"2023-08-21T06:45:10.586382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(augmented_labels)\nlabel_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:45:10.588982Z","iopub.execute_input":"2023-08-21T06:45:10.589299Z","iopub.status.idle":"2023-08-21T06:45:10.598522Z","shell.execute_reply.started":"2023-08-21T06:45:10.589270Z","shell.execute_reply":"2023-08-21T06:45:10.597707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = to_categorical(encoded_labels, num_classes)\nunique_labels_set = set(tuple(label) for label in labels)\nfor unique_label in unique_labels_list:\n    print(unique_label)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:45:19.564597Z","iopub.execute_input":"2023-08-21T06:45:19.565535Z","iopub.status.idle":"2023-08-21T06:45:19.575879Z","shell.execute_reply.started":"2023-08-21T06:45:19.565500Z","shell.execute_reply":"2023-08-21T06:45:19.574996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx = base_model.layers[-1].output\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nlearning_rate = 0.0001\noptimizer = Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:45:20.407533Z","iopub.execute_input":"2023-08-21T06:45:20.407877Z","iopub.status.idle":"2023-08-21T06:45:27.363131Z","shell.execute_reply.started":"2023-08-21T06:45:20.407850Z","shell.execute_reply":"2023-08-21T06:45:27.361831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 3\nepochs = 3\nbatch_size = 32\nkf = KFold(n_splits=k, shuffle=True)\n\naccuracy_values = []\nprecision_values = []\nrecall_values = []\nf1_score_values = []\n\nconfusion_matrices = []\nall_true_labels = []\nall_pred_labels = []\nmodel_history = []\n\nfor fold, (train_index, test_index) in enumerate(kf.split(images), 1):\n    print(\"Fold:\", fold)\n    X_train_fold, X_test_fold = images[train_index], images[test_index]\n    y_train_fold, y_test_fold = labels[train_index], labels[test_index]\n\n    history = model.fit(X_train_fold, y_train_fold, epochs=epochs, batch_size=batch_size)\n\n    y_pred = model.predict(X_test_fold)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(y_test_fold, axis=1)\n\n    \n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    report = classification_report(y_true_labels, y_pred_labels, output_dict=True)\n    \n    confusion_matrices.append(cm)\n    accuracy_values.append(report['accuracy'])\n    precision_values.append(report['weighted avg']['precision'])\n    recall_values.append(report['weighted avg']['recall'])\n    f1_score_values.append(report['weighted avg']['f1-score'])\n\n    all_true_labels.extend(y_true_labels)\n    all_pred_labels.extend(y_pred)\n    model_history.append(history)\n    \navg_accuracy = np.mean(accuracy_values)\navg_weighted_precision = np.mean(precision_values)\navg_weighted_recall = np.mean(recall_values)\navg_weighted_f1_score = np.mean(f1_score_values)\n\nprint('Average accuracy:', avg_accuracy)\nprint('Average weighted precision:', avg_weighted_precision)\nprint('Average weighted recall:', avg_weighted_recall)\nprint('Average weighted f1 score:', avg_weighted_f1_score)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:45:27.364951Z","iopub.execute_input":"2023-08-21T06:45:27.365333Z","iopub.status.idle":"2023-08-21T07:26:39.732189Z","shell.execute_reply.started":"2023-08-21T06:45:27.365305Z","shell.execute_reply":"2023-08-21T07:26:39.731077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pred_labels = np.array(all_pred_labels)\nall_true_labels = np.array(all_true_labels)\nn_classes = len(np.unique(all_true_labels))\nall_true_labels_binarized = label_binarize(all_true_labels, classes=range(n_classes))\ntrue = all_true_labels_binarized.ravel()\npred = all_pred_labels.ravel()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T07:27:01.889487Z","iopub.execute_input":"2023-08-21T07:27:01.890493Z","iopub.status.idle":"2023-08-21T07:27:01.898375Z","shell.execute_reply.started":"2023-08-21T07:27:01.890447Z","shell.execute_reply":"2023-08-21T07:27:01.897545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = pd.DataFrame({\n    'True_Class': true,\n    'Pred_Class': pred,\n})\n\nroc_values.to_csv('/kaggle/working/BITVehicle_DenseNet121_ROC.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T07:27:02.223780Z","iopub.execute_input":"2023-08-21T07:27:02.224453Z","iopub.status.idle":"2023-08-21T07:27:02.510667Z","shell.execute_reply.started":"2023-08-21T07:27:02.224410Z","shell.execute_reply":"2023-08-21T07:27:02.509603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_curves = pd.DataFrame({\n    'Precision': precision_values,\n    'Recall': recall_values,\n    'F1_score': f1_score_values,\n})\n\nlearning_curves.to_csv('/kaggle/working/BITVehicle_DenseNet121_Learning.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T07:27:02.752978Z","iopub.execute_input":"2023-08-21T07:27:02.753262Z","iopub.status.idle":"2023-08-21T07:27:02.759385Z","shell.execute_reply.started":"2023-08-21T07:27:02.753236Z","shell.execute_reply":"2023-08-21T07:27:02.758591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_values = pd.DataFrame({\n    'History': model_history\n})\n\nhistory_values.to_csv('/kaggle/working/BITVehicle_DenseNet121_History.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T07:27:03.592283Z","iopub.execute_input":"2023-08-21T07:27:03.593183Z","iopub.status.idle":"2023-08-21T07:27:03.598164Z","shell.execute_reply.started":"2023-08-21T07:27:03.593154Z","shell.execute_reply":"2023-08-21T07:27:03.597341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n\nfor fold, cm in enumerate(confusion_matrices, 1):\n    combined_conf_matrix += cm\n\nconf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(8, num_labels * 0.5), 12)\nfig_height = max(6, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=0, fontsize=10)\nplt.yticks(rotation=0, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig('/kaggle/working/confusion_matrix1-BITVehicle_DenseNet121.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T07:27:04.142298Z","iopub.execute_input":"2023-08-21T07:27:04.142640Z","iopub.status.idle":"2023-08-21T07:27:06.685261Z","shell.execute_reply.started":"2023-08-21T07:27:04.142610Z","shell.execute_reply":"2023-08-21T07:27:06.684202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(8, num_labels * 0.5), 12)\nfig_height = max(6, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=45, fontsize=10)\nplt.yticks(rotation=45, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig('/kaggle/working/confusion_matrix2-BITVehicle_DenseNet121.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T07:27:06.687003Z","iopub.execute_input":"2023-08-21T07:27:06.687325Z","iopub.status.idle":"2023-08-21T07:27:07.930631Z","shell.execute_reply.started":"2023-08-21T07:27:06.687296Z","shell.execute_reply":"2023-08-21T07:27:07.929514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}