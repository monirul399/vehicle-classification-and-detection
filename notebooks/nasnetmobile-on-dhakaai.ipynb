{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6333223,"sourceType":"datasetVersion","datasetId":3645581}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imbalanced-learn\n!pip install seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T06:22:34.485266Z","iopub.execute_input":"2023-08-21T06:22:34.485617Z","iopub.status.idle":"2023-08-21T06:22:46.012120Z","shell.execute_reply.started":"2023-08-21T06:22:34.485587Z","shell.execute_reply":"2023-08-21T06:22:46.010960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom imblearn.over_sampling import SMOTE\nfrom tensorflow.keras.applications.nasnet import NASNetMobile, preprocess_input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:22:46.013998Z","iopub.execute_input":"2023-08-21T06:22:46.014341Z","iopub.status.idle":"2023-08-21T06:23:28.976618Z","shell.execute_reply.started":"2023-08-21T06:22:46.014307Z","shell.execute_reply":"2023-08-21T06:23:28.975696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"read_data = \"/kaggle/input/dhakaai/dhakaai-dataset.h5\"\nwith h5py.File(read_data, 'r') as hf:\n    image = hf['images'][:]\n    label = hf['labels'][:]\n    valid_indices = [i for i, lbl in enumerate(label) if lbl != b'taxi']\n\n    images = image[valid_indices]\n    labels = label[valid_indices]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:23:28.978113Z","iopub.execute_input":"2023-08-21T06:23:28.978908Z","iopub.status.idle":"2023-08-21T06:23:44.621220Z","shell.execute_reply.started":"2023-08-21T06:23:28.978856Z","shell.execute_reply":"2023-08-21T06:23:44.620293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of images: ',len(images))\nprint('Total number of labels: ',len(labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:23:44.623532Z","iopub.execute_input":"2023-08-21T06:23:44.623953Z","iopub.status.idle":"2023-08-21T06:23:44.629861Z","shell.execute_reply.started":"2023-08-21T06:23:44.623913Z","shell.execute_reply":"2023-08-21T06:23:44.628764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_classes, class_counts = np.unique(labels, return_counts=True)\nfor class_label, count in zip(unique_classes, class_counts):\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:23:44.631268Z","iopub.execute_input":"2023-08-21T06:23:44.631669Z","iopub.status.idle":"2023-08-21T06:23:44.650359Z","shell.execute_reply.started":"2023-08-21T06:23:44.631630Z","shell.execute_reply":"2023-08-21T06:23:44.649290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_images = [Image.fromarray((image * 255).astype(np.uint8)).resize((224, 224)) for image in images]\nresized_images = np.array([preprocess_input(np.array(image)) for image in resized_images])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:26:26.782288Z","iopub.execute_input":"2023-08-21T06:26:26.782725Z","iopub.status.idle":"2023-08-21T06:26:41.686862Z","shell.execute_reply.started":"2023-08-21T06:26:26.782691Z","shell.execute_reply":"2023-08-21T06:26:41.685785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_low_samples = 1045\n\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\nlabel_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n\nflattened_images_reshaped = np.array([img.flatten() for img in resized_images])\nnum_samples, num_features = flattened_images_reshaped.shape\n\noversampled_images = []\noversampled_labels = []\n\nto_sample_images = []\nto_sample_labels = []\n\nunique_classes, class_counts = np.unique(encoded_labels, return_counts=True)\n\nfor class_label, count in zip(unique_classes, class_counts):\n    class_indices = np.where(encoded_labels == class_label)[0]\n    \n    if count <= threshold_low_samples:\n        to_sample_images.extend(flattened_images_reshaped[class_indices])\n        to_sample_labels.extend(encoded_labels[class_indices])\n\nif len(to_sample_images) >= 3:\n    smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=2)\n    oversampled_class_images, oversampled_class_labels = smote.fit_resample(to_sample_images, to_sample_labels)\n\n    oversampled_images.extend(oversampled_class_images)\n    oversampled_labels.extend(oversampled_class_labels)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:26:41.688477Z","iopub.execute_input":"2023-08-21T06:26:41.688767Z","iopub.status.idle":"2023-08-21T06:36:36.919510Z","shell.execute_reply.started":"2023-08-21T06:26:41.688742Z","shell.execute_reply":"2023-08-21T06:36:36.918088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of sampled images: ',len(oversampled_images))\nprint('Total number of sampled labels: ',len(oversampled_labels))\n\nunique_classes_aug, class_counts_aug = np.unique(oversampled_labels, return_counts=True)\nfor class_label, count in zip(unique_classes_aug, class_counts_aug):\n    print(f\"Class {class_label}: {count} samples\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:36:36.921167Z","iopub.execute_input":"2023-08-21T06:36:36.921592Z","iopub.status.idle":"2023-08-21T06:36:36.930986Z","shell.execute_reply.started":"2023-08-21T06:36:36.921552Z","shell.execute_reply":"2023-08-21T06:36:36.929974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_images = np.array(oversampled_images).reshape(-1, 224,224,3)\nprint('Total number of sampled images: ',len(original_images))\nprint('Total number of sampled labels: ',len(oversampled_labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:36:54.425295Z","iopub.execute_input":"2023-08-21T06:36:54.425735Z","iopub.status.idle":"2023-08-21T06:39:49.811727Z","shell.execute_reply.started":"2023-08-21T06:36:54.425701Z","shell.execute_reply":"2023-08-21T06:39:49.810439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = to_categorical(encoded_labels, num_classes)\nunique_labels_set = set(tuple(label) for label in labels)\nfor unique_label in unique_labels_list:\n    print(unique_label)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:39:49.813599Z","iopub.execute_input":"2023-08-21T06:39:49.813946Z","iopub.status.idle":"2023-08-21T06:39:49.843543Z","shell.execute_reply.started":"2023-08-21T06:39:49.813916Z","shell.execute_reply":"2023-08-21T06:39:49.842422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx = base_model.layers[-1].output\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nlearning_rate = 0.0001\noptimizer = Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:39:55.220010Z","iopub.execute_input":"2023-08-21T06:39:55.220612Z","iopub.status.idle":"2023-08-21T06:40:08.678432Z","shell.execute_reply.started":"2023-08-21T06:39:55.220565Z","shell.execute_reply":"2023-08-21T06:40:08.676971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 3\nepochs = 3\nbatch_size = 32\nkf = KFold(n_splits=k, shuffle=True)\n\naccuracy_values = []\nprecision_values = []\nrecall_values = []\nf1_score_values = []\n\nconfusion_matrices = []\nall_true_labels = []\nall_pred_labels = []\nmodel_history = []\n\nfor fold, (train_index, test_index) in enumerate(kf.split(original_images), 1):\n    print(\"Fold:\", fold)\n    X_train_fold, X_test_fold = original_images[train_index], original_images[test_index]\n    y_train_fold, y_test_fold = labels[train_index], labels[test_index]\n\n    history = model.fit(X_train_fold, y_train_fold, epochs=epochs, batch_size=batch_size)\n\n    y_pred = model.predict(X_test_fold)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(y_test_fold, axis=1)\n\n    \n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    report = classification_report(y_true_labels, y_pred_labels, output_dict=True)\n    \n    confusion_matrices.append(cm)\n    accuracy_values.append(report['accuracy'])\n    precision_values.append(report['weighted avg']['precision'])\n    recall_values.append(report['weighted avg']['recall'])\n    f1_score_values.append(report['weighted avg']['f1-score'])\n\n    all_true_labels.extend(y_true_labels)\n    all_pred_labels.extend(y_pred)\n    model_history.append(history)\n    \navg_accuracy = np.mean(accuracy_values)\navg_weighted_precision = np.mean(precision_values)\navg_weighted_recall = np.mean(recall_values)\navg_weighted_f1_score = np.mean(f1_score_values)\n\nprint('Average accuracy:', avg_accuracy)\nprint('Average weighted precision:', avg_weighted_precision)\nprint('Average weighted recall:', avg_weighted_recall)\nprint('Average weighted f1 score:', avg_weighted_f1_score)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:40:10.824150Z","iopub.execute_input":"2023-08-21T06:40:10.824546Z","iopub.status.idle":"2023-08-21T06:56:59.336674Z","shell.execute_reply.started":"2023-08-21T06:40:10.824515Z","shell.execute_reply":"2023-08-21T06:56:59.335488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pred_labels = np.array(all_pred_labels)\nall_true_labels = np.array(all_true_labels)\nn_classes = len(np.unique(all_true_labels))\nall_true_labels_binarized = label_binarize(all_true_labels, classes=range(n_classes))\ntrue = all_true_labels_binarized.ravel()\npred = all_pred_labels.ravel()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:57:12.862774Z","iopub.execute_input":"2023-08-21T06:57:12.864033Z","iopub.status.idle":"2023-08-21T06:57:12.889403Z","shell.execute_reply.started":"2023-08-21T06:57:12.863983Z","shell.execute_reply":"2023-08-21T06:57:12.888133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = pd.DataFrame({\n    'True_Class': true,\n    'Pred_Class': pred,\n})\n\nroc_values.to_csv('/kaggle/working/DhakaAI_NASNetMobile_ROC.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:57:13.089513Z","iopub.execute_input":"2023-08-21T06:57:13.089987Z","iopub.status.idle":"2023-08-21T06:57:13.932858Z","shell.execute_reply.started":"2023-08-21T06:57:13.089949Z","shell.execute_reply":"2023-08-21T06:57:13.931536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_curves = pd.DataFrame({\n    'Precision': precision_values,\n    'Recall': recall_values,\n    'F1_score': f1_score_values,\n})\n\nlearning_curves.to_csv('/kaggle/working/DhakaAI_NASNetMobile_Learning.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:57:13.934777Z","iopub.execute_input":"2023-08-21T06:57:13.935106Z","iopub.status.idle":"2023-08-21T06:57:13.942189Z","shell.execute_reply.started":"2023-08-21T06:57:13.935080Z","shell.execute_reply":"2023-08-21T06:57:13.941282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_values = pd.DataFrame({\n    'History': model_history\n})\n\nhistory_values.to_csv('/kaggle/working/DhakaAI_NASNetMobile_History.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:57:13.943421Z","iopub.execute_input":"2023-08-21T06:57:13.943777Z","iopub.status.idle":"2023-08-21T06:57:13.952462Z","shell.execute_reply.started":"2023-08-21T06:57:13.943745Z","shell.execute_reply":"2023-08-21T06:57:13.951598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n\nfor fold, cm in enumerate(confusion_matrices, 1):\n    combined_conf_matrix += cm\n\nconf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(20, num_labels * 0.5), 30)\nfig_height = max(20, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=45, fontsize=10)\nplt.yticks(rotation=0, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig('/kaggle/working/confusion_matrix1-DhakaAI_NASNetMobile.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:57:14.173956Z","iopub.execute_input":"2023-08-21T06:57:14.174403Z","iopub.status.idle":"2023-08-21T06:57:18.193894Z","shell.execute_reply.started":"2023-08-21T06:57:14.174367Z","shell.execute_reply":"2023-08-21T06:57:18.192623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(20, num_labels * 0.5), 30)\nfig_height = max(20, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=45, fontsize=10)\nplt.yticks(rotation=45, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig('/kaggle/working/confusion_matrix2-DhakaAI_NASNetMobile.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:57:18.195707Z","iopub.execute_input":"2023-08-21T06:57:18.196019Z","iopub.status.idle":"2023-08-21T06:57:24.449817Z","shell.execute_reply.started":"2023-08-21T06:57:18.195992Z","shell.execute_reply":"2023-08-21T06:57:24.448659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}