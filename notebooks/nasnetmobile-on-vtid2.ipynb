{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6318897,"sourceType":"datasetVersion","datasetId":3636223}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install seaborn","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:27:14.653180Z","iopub.execute_input":"2023-08-18T20:27:14.654070Z","iopub.status.idle":"2023-08-18T20:27:20.729741Z","shell.execute_reply.started":"2023-08-18T20:27:14.654032Z","shell.execute_reply":"2023-08-18T20:27:20.728364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications.nasnet import NASNetMobile, preprocess_input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-18T20:27:20.732351Z","iopub.execute_input":"2023-08-18T20:27:20.733172Z","iopub.status.idle":"2023-08-18T20:28:03.176174Z","shell.execute_reply.started":"2023-08-18T20:27:20.733118Z","shell.execute_reply":"2023-08-18T20:28:03.175165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with h5py.File('/kaggle/input/vtid2-dataset/vtid2_dataset.h5', 'r') as file:\n    images = file['images'][:]\n    labels = file['labels'][:]","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:28:03.177528Z","iopub.execute_input":"2023-08-18T20:28:03.178192Z","iopub.status.idle":"2023-08-18T20:28:17.567146Z","shell.execute_reply.started":"2023-08-18T20:28:03.178145Z","shell.execute_reply":"2023-08-18T20:28:17.565765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of images: ',len(images))\nprint('Total number of labels: ',len(labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:29:00.300038Z","iopub.execute_input":"2023-08-18T20:29:00.300519Z","iopub.status.idle":"2023-08-18T20:29:00.306546Z","shell.execute_reply.started":"2023-08-18T20:29:00.300483Z","shell.execute_reply":"2023-08-18T20:29:00.305634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_images = [Image.fromarray(image).resize((224, 224)) for image in images]\nresized_images = np.array([preprocess_input(np.array(image)) for image in resized_images])","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:29:00.570513Z","iopub.execute_input":"2023-08-18T20:29:00.571241Z","iopub.status.idle":"2023-08-18T20:29:13.820698Z","shell.execute_reply.started":"2023-08-18T20:29:00.571188Z","shell.execute_reply":"2023-08-18T20:29:13.819469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_brightness(image, factor):\n    image = image.astype(np.float32)\n    augmented_image = image + factor\n    augmented_image = np.clip(augmented_image, 0, 255)\n    augmented_image = augmented_image.astype(np.uint8)\n    return augmented_image\n\ndef flip_image(image, flip_code):\n    return cv2.flip(image, flip_code)\n\ndef rotate_image(image, angle):\n    rows, cols = image.shape[:2]\n    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n    return cv2.warpAffine(image, M, (cols, rows))\n\ndef zoom_image(image, zoom_factor):\n    rows, cols = image.shape[:2]\n    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 0, zoom_factor)\n    return cv2.warpAffine(image, M, (cols, rows))\n\ndef shift_image(image, dx, dy):\n    rows, cols = image.shape[:2]\n    M = np.float32([[1, 0, dx], [0, 1, dy]])\n    return cv2.warpAffine(image, M, (cols, rows))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:29:13.822643Z","iopub.execute_input":"2023-08-18T20:29:13.823042Z","iopub.status.idle":"2023-08-18T20:29:13.833836Z","shell.execute_reply.started":"2023-08-18T20:29:13.823007Z","shell.execute_reply":"2023-08-18T20:29:13.832917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_images = []\naugmented_labels = []\n\nfor img, label in zip(resized_images, labels):\n    augmented_img_brightness = adjust_brightness(img, 50)\n\n    augmented_img_flip_horizontal = flip_image(img, 1)\n    augmented_img_flip_vertical = flip_image(img, 0)\n\n    augmented_img_rotate = rotate_image(img, 30)\n\n    augmented_img_zoom = zoom_image(img, 1.2)\n\n    augmented_img_shift = shift_image(img, 20, 20)\n\n    augmented_images.extend([\n        img,\n        augmented_img_brightness,\n        augmented_img_flip_horizontal,\n        augmented_img_flip_vertical,\n        augmented_img_rotate,\n        augmented_img_zoom,\n        augmented_img_shift\n    ])\n\n    augmented_labels.extend([label] * 7)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:29:13.834963Z","iopub.execute_input":"2023-08-18T20:29:13.835242Z","iopub.status.idle":"2023-08-18T20:29:32.326830Z","shell.execute_reply.started":"2023-08-18T20:29:13.835218Z","shell.execute_reply":"2023-08-18T20:29:32.325763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of augmented images: ',len(augmented_images))\nprint('Total number of augmented labels: ',len(augmented_labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:29:32.328761Z","iopub.execute_input":"2023-08-18T20:29:32.329101Z","iopub.status.idle":"2023-08-18T20:29:32.334321Z","shell.execute_reply.started":"2023-08-18T20:29:32.329073Z","shell.execute_reply":"2023-08-18T20:29:32.333435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.array(augmented_images)\nnum_classes = len(np.unique(augmented_labels))\nprint('Number of classes',num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:36:35.366001Z","iopub.execute_input":"2023-08-18T20:36:35.367093Z","iopub.status.idle":"2023-08-18T20:36:40.636507Z","shell.execute_reply.started":"2023-08-18T20:36:35.367045Z","shell.execute_reply":"2023-08-18T20:36:40.635326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(augmented_labels)\nlabel_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:36:40.638287Z","iopub.execute_input":"2023-08-18T20:36:40.638613Z","iopub.status.idle":"2023-08-18T20:36:40.650502Z","shell.execute_reply.started":"2023-08-18T20:36:40.638584Z","shell.execute_reply":"2023-08-18T20:36:40.649702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = to_categorical(encoded_labels, num_classes)\nunique_labels_set = set(tuple(label) for label in labels)\nfor unique_label in unique_labels_list:\n    print(unique_label)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:36:40.651699Z","iopub.execute_input":"2023-08-18T20:36:40.652116Z","iopub.status.idle":"2023-08-18T20:36:40.668053Z","shell.execute_reply.started":"2023-08-18T20:36:40.652085Z","shell.execute_reply":"2023-08-18T20:36:40.667252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx = base_model.layers[-1].output\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nlearning_rate = 0.0001\noptimizer = Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:36:40.669617Z","iopub.execute_input":"2023-08-18T20:36:40.669904Z","iopub.status.idle":"2023-08-18T20:36:51.470008Z","shell.execute_reply.started":"2023-08-18T20:36:40.669866Z","shell.execute_reply":"2023-08-18T20:36:51.468542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 3\nepochs = 3\nbatch_size = 32\nkf = KFold(n_splits=k, shuffle=True)\n\naccuracy_values = []\nprecision_values = []\nrecall_values = []\nf1_score_values = []\n\nconfusion_matrices = []\nall_true_labels = []\nall_pred_labels = []\nmodel_history = []\n\nfor fold, (train_index, test_index) in enumerate(kf.split(images), 1):\n    print(\"Fold:\", fold)\n    X_train_fold, X_test_fold = images[train_index], images[test_index]\n    y_train_fold, y_test_fold = labels[train_index], labels[test_index]\n\n    history = model.fit(X_train_fold, y_train_fold, epochs=epochs, batch_size=batch_size)\n\n    y_pred = model.predict(X_test_fold)\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(y_test_fold, axis=1)\n\n    \n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    report = classification_report(y_true_labels, y_pred_labels, output_dict=True)\n    \n    confusion_matrices.append(cm)\n    accuracy_values.append(report['accuracy'])\n    precision_values.append(report['weighted avg']['precision'])\n    recall_values.append(report['weighted avg']['recall'])\n    f1_score_values.append(report['weighted avg']['f1-score'])\n\n    all_true_labels.extend(y_true_labels)\n    all_pred_labels.extend(y_pred)\n    model_history.append(history)\n    \navg_accuracy = np.mean(accuracy_values)\navg_weighted_precision = np.mean(precision_values)\navg_weighted_recall = np.mean(recall_values)\navg_weighted_f1_score = np.mean(f1_score_values)\n\nprint('Average accuracy:', avg_accuracy)\nprint('Average weighted precision:', avg_weighted_precision)\nprint('Average weighted recall:', avg_weighted_recall)\nprint('Average weighted f1 score:', avg_weighted_f1_score)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T20:38:46.752123Z","iopub.execute_input":"2023-08-18T20:38:46.752591Z","iopub.status.idle":"2023-08-18T21:00:49.766813Z","shell.execute_reply.started":"2023-08-18T20:38:46.752552Z","shell.execute_reply":"2023-08-18T21:00:49.765353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pred_labels = np.array(all_pred_labels)\nall_true_labels = np.array(all_true_labels)\nn_classes = len(np.unique(all_true_labels))\nall_true_labels_binarized = label_binarize(all_true_labels, classes=range(n_classes))\ntrue = all_true_labels_binarized.ravel()\npred = all_pred_labels.ravel()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:04:48.338991Z","iopub.execute_input":"2023-08-18T21:04:48.339466Z","iopub.status.idle":"2023-08-18T21:04:48.370980Z","shell.execute_reply.started":"2023-08-18T21:04:48.339431Z","shell.execute_reply":"2023-08-18T21:04:48.369916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = pd.DataFrame({\n    'True_Class': true,\n    'Pred_Class': pred,\n})\n\nroc_values.to_csv('/kaggle/working/VTID2_NASNetMobile_ROC.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:04:49.457954Z","iopub.execute_input":"2023-08-18T21:04:49.458413Z","iopub.status.idle":"2023-08-18T21:04:49.816224Z","shell.execute_reply.started":"2023-08-18T21:04:49.458380Z","shell.execute_reply":"2023-08-18T21:04:49.814914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_curves = pd.DataFrame({\n    'Precision': precision_values,\n    'Recall': recall_values,\n    'F1_score': f1_score_values,\n})\n\nlearning_curves.to_csv('/kaggle/working/VTID2_NASNetMobile_Learning.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:04:50.315169Z","iopub.execute_input":"2023-08-18T21:04:50.315490Z","iopub.status.idle":"2023-08-18T21:04:50.322698Z","shell.execute_reply.started":"2023-08-18T21:04:50.315463Z","shell.execute_reply":"2023-08-18T21:04:50.321738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_values = pd.DataFrame({\n    'History': model_history\n})\n\nhistory_values.to_csv('/kaggle/working/VTID2_NASNetMobile_History.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:04:53.439907Z","iopub.execute_input":"2023-08-18T21:04:53.440318Z","iopub.status.idle":"2023-08-18T21:04:53.447821Z","shell.execute_reply.started":"2023-08-18T21:04:53.440286Z","shell.execute_reply":"2023-08-18T21:04:53.446712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n\nfor fold, cm in enumerate(confusion_matrices, 1):\n    combined_conf_matrix += cm\n\nconf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(8, num_labels * 0.5), 12)\nfig_height = max(6, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=0, fontsize=10)\nplt.yticks(rotation=0, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig('/kaggle/working/confusion_matrix1-VTID2_NASNetMobile.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:04:54.595606Z","iopub.execute_input":"2023-08-18T21:04:54.596404Z","iopub.status.idle":"2023-08-18T21:04:55.943952Z","shell.execute_reply.started":"2023-08-18T21:04:54.596373Z","shell.execute_reply":"2023-08-18T21:04:55.942762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix_labels = [label_mapping[i] for i in range(len(label_mapping))]\nconf_matrix_labels = [label.decode('utf-8')[0:] for label in conf_matrix_labels]\n\nnum_labels = len(conf_matrix_labels)\nfig_width = min(max(8, num_labels * 0.5), 12)\nfig_height = max(6, num_labels * 0.4)\n\nplt.figure(figsize=(fig_width, fig_height))\nplt.rcParams['figure.dpi'] = 300\n\nsns.heatmap(combined_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=conf_matrix_labels, yticklabels=conf_matrix_labels)\nplt.xticks(rotation=45, fontsize=10)\nplt.yticks(rotation=45, fontsize=10)\nplt.xlabel(\"Predicted Classes\", fontsize=12)\nplt.ylabel(\"True Classes\", fontsize=12)\nplt.savefig('/kaggle/working/confusion_matrix2-VTID2_NASNetMobile.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T21:05:00.100826Z","iopub.execute_input":"2023-08-18T21:05:00.101226Z","iopub.status.idle":"2023-08-18T21:05:01.197859Z","shell.execute_reply.started":"2023-08-18T21:05:00.101195Z","shell.execute_reply":"2023-08-18T21:05:01.196744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}